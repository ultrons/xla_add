{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a901316a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is a simple illustration of op-sharded (SPMD) style model parallel training using PyTorch/XLA.\n",
    "The implementation and core concepts here are from [NVIDIA/Megatron](https://github.com/NVIDIA/Megatron-LM)\n",
    "\n",
    "The word SPMD stands from Single Program Multiple Data. The essence of this method of Model Parallelism is that sharding is done in such a way that each core executes program of identical shape. \n",
    "\n",
    "We illustrate SPMD training using a two layer network example for linear regression.\n",
    "<img src=\"img\\default-network.png\" />\n",
    "The two colors in each of the layers indicate how we are going to shard them.\n",
    "Using ColumnParallelLinear and RowParallelLinear layers from Megatron's mpu module (refactored here to work with PyTorch/XLA)\n",
    "<img src=\"img\\mp-network.png\" />\n",
    "\n",
    "\n",
    "Notice that f & g are conjugate functions. f is an identity function in the forward pass and an all reduce in the backward pass. g is all_reduce in the forward pass and identity in the backward pass.\n",
    "\n",
    "With this setup in effect one replica of model is split into two:\n",
    "  \n",
    "<img src=\"img\\sharded-replica.png\" />\n",
    "\n",
    "\n",
    "For example if you are using 8 total cores (world size), model_parallel world_size will be 2 and you can have 4 data\n",
    "\n",
    "\n",
    "## Setup\n",
    "XRT_TPU_CONFIG\n",
    "Defines where XRT Server will be running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f6b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XRT_TPU_CONFIG'] = 'localservice;0;localhost:51011'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa70226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch_xla.debug.metrics as met\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from xla_add.mpu.layers import (\n",
    "    ColumnParallelLinear,\n",
    "    RowParallelLinear,\n",
    ")\n",
    "\n",
    "import xla_add.mpu as mpu\n",
    "import xla_add.mpu.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e4966",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "Creating a simple linear dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d1b054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 2048\n",
    "input_dim = 1\n",
    "xs = np.random.normal(size=(num_samples, input_dim))\n",
    "noise = np.random.normal(scale=0.1, size=(num_samples,input_dim))\n",
    "#ys = (xs**2) * 3 - 1 + noise\n",
    "ys = xs * 3 - 1 + noise\n",
    "\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "\n",
    "inputs = torch.from_numpy(xs)\n",
    "targets = torch.from_numpy(ys)\n",
    "dataset = torch.utils.data.TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceecea6",
   "metadata": {},
   "source": [
    "## Define the Network\n",
    "Notice that we use ColumnParallelLinear, and RowParallelLinear for consecutive layers.\n",
    "For more insights on how to select these layers to replace your linear layer, please refer to [NVIDIA/Megatron](https://arxiv.org/pdf/1909.08053.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7463eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sample_network, self).__init__()\n",
    "        #self.linear1 = nn.Linear(64, 32)\n",
    "        #self.linear2 = nn.Linear(32, 10)\n",
    "        self.linear1 = ColumnParallelLinear(1, 32, gather_output=False, bias=False)\n",
    "        self.linear2 = RowParallelLinear(32, 1, input_is_parallel=True, bias=False)\n",
    "        self.nl = nn.ReLU()\n",
    "        #self.out = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.nl(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5848061",
   "metadata": {},
   "source": [
    "# Define per core program\n",
    "\n",
    "When running Model parallel training, pay attention to the distributed sampler and gradient all-reduce operation\n",
    "The data parallel rank, world size and groups are not the default i.e. not the same as the default data parallel training. \n",
    "\n",
    "Please see the comments inline for concrete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79af1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_core_action(index):\n",
    "    # MP Setup\n",
    "    tensor_model_parallel_size = 2\n",
    "    # This will initialize the variables for sharded layers to work correctly\n",
    "    mpu.initialize_model_parallel(tensor_model_parallel_size)\n",
    "    \n",
    "    \n",
    "    data_parallel_rank = mpu.initialize.get_data_parallel_rank()\n",
    "    data_parallel_world_size = mpu.initialize.get_data_parallel_world_size()\n",
    "    data_parallel_group = mpu.initialize.get_data_parallel_global_group()\n",
    "\n",
    "    # XLA Device abstraction\n",
    "    device = xm.xla_device()\n",
    "    model = sample_network().to(device)\n",
    "\n",
    "    # Notice the num_replica and rank parameters of the sampler\n",
    "    # Data parallel rank of the two devices which are holding shards of the same replica will be same\n",
    "    distributed_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "          dataset,\n",
    "          num_replicas=(xm.xrt_world_size() // tensor_model_parallel_size),\n",
    "          rank=data_parallel_rank,\n",
    "          shuffle=True)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, sampler=distributed_sampler)\n",
    "\n",
    "    parallel_loader = pl.MpDeviceLoader(dataloader, device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "    num_epochs = 10\n",
    "    for e in range(num_epochs):\n",
    "        for x, y in parallel_loader:\n",
    "            y_hat = model(x)\n",
    "            loss = torch.sum((y - y_hat)**2 / y.numel())\n",
    "            # Optionally print graph of the forward pass to examine sharding\n",
    "            #print(torch_xla._XLAC._get_xla_tensors_text([loss]))\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer, groups=data_parallel_group)\n",
    "            #print(f\"Debug: Rank:{xm.get_ordinal()} DP Group:{data_parallel_group} loss :{loss}\")\n",
    "        xm.master_print(f\"Epoch:{e}, loss :{loss}\")\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    #xm.rendezvous('All processes meet here!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc3f82",
   "metadata": {},
   "source": [
    "# Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c75eec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 00:41:10.453247: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:10.453308: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing tensor model parallel with size 2\n",
      "> initializing pipeline model parallel with size 1\n",
      ">>>> _TENSOR_MODEL_PARALLEL_GROUP: [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 00:41:34.862263: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:34.862331: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2021-10-21 00:41:34.971344: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:34.971407: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2021-10-21 00:41:36.561079: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:36.561141: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2021-10-21 00:41:36.788745: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:36.788803: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2021-10-21 00:41:37.274688: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:37.274750: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2021-10-21 00:41:37.657264: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:37.657325: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "2021-10-21 00:41:40.150849: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:40.150904: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, loss :9.13158130645752\n",
      "Epoch:1, loss :8.9047212600708\n",
      "Epoch:2, loss :8.521275520324707\n",
      "Epoch:3, loss :7.9740891456604\n",
      "Epoch:4, loss :7.249765872955322\n",
      "Epoch:5, loss :6.334079742431641\n",
      "Epoch:6, loss :5.220804214477539\n",
      "Epoch:7, loss :3.940500497817993\n",
      "Epoch:8, loss :2.6096081733703613\n",
      "Epoch:9, loss :1.4902187585830688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 00:41:10.453247: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2021-10-21 00:41:10.453308: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "xmp.spawn(per_core_action, nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221c725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
